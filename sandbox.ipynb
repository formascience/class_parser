{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6f5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 15:48:19 - audio_extractor.audio_processor - INFO - Extracting audio from /Users/youssefjanjar/Documents/formascience/volume/cours_1.mp4\n",
      "2025-07-27 15:48:23 - audio_extractor.audio_processor - INFO - Audio extracted successfully: /Users/youssefjanjar/Documents/formascience/volume/transcripts/cours_1_audio.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/youssefjanjar/Documents/formascience/volume/transcripts/cours_1_audio.wav'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from audio_extractor.audio_processor import AudioExtractor, AudioChunker, VideoToTextPipeline\n",
    "\n",
    "video_path = \"/Users/youssefjanjar/Documents/formascience/volume/cours_1.mp4\"\n",
    "output_path = \"/Users/youssefjanjar/Documents/formascience/volume/transcripts\"\n",
    "\n",
    "\n",
    "\n",
    "audio_extractor = AudioExtractor()\n",
    "audio_extractor.extract_audio(video_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "209ab430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 15:59:51 - audio_extractor.audio_processor - INFO - Splitting audio into 3.0 minute chunks\n",
      "2025-07-27 15:59:51 - audio_extractor.audio_processor - INFO - Output directory: /Users/youssefjanjar/Documents/formascience/volume/audio/cours_1_audio_chunks\n",
      "2025-07-27 15:59:52 - audio_extractor.audio_processor - INFO - Created 25 audio chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 25 chunks\n",
      "Chunks saved in: /Users/youssefjanjar/Documents/formascience/volume/audio/cours_1_audio_chunks\n",
      "  Chunk 1: cours_1_audio_chunk_001.wav\n",
      "  Chunk 2: cours_1_audio_chunk_002.wav\n",
      "  Chunk 3: cours_1_audio_chunk_003.wav\n"
     ]
    }
   ],
   "source": [
    "from audio_extractor.audio_processor import AudioChunker\n",
    "import os\n",
    "\n",
    "audio_chunker = AudioChunker()\n",
    "audio_path = \"/Users/youssefjanjar/Documents/formascience/volume/audio/cours_1_audio.wav\"\n",
    "output_path = \"/Users/youssefjanjar/Documents/formascience/volume/transcripts\"\n",
    "\n",
    "# Initialize chunker\n",
    "chunker = AudioChunker()\n",
    "\n",
    "# Split audio into 3-minute chunks\n",
    "# This creates a folder named \"audio_filename_chunks\" automatically\n",
    "chunk_paths = chunker.split_audio(\n",
    "    audio_path, \n",
    "    chunk_duration_minutes=3.0  # 3-minute chunks\n",
    ")\n",
    "\n",
    "print(f\"Created {len(chunk_paths)} chunks\")\n",
    "print(f\"Chunks saved in: {os.path.dirname(chunk_paths[0]) if chunk_paths else 'N/A'}\")\n",
    "\n",
    "# Show first few chunk paths\n",
    "for i, chunk in enumerate(chunk_paths[:3], 1):\n",
    "    print(f\"  Chunk {i}: {os.path.basename(chunk)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f725dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transcription.whisper_client import WhisperTranscriber\n",
    "prompt = \"\"\"\n",
    "Transcription académique d'un cours de médecine universitaire, en français.\n",
    "Le locuteur est un professeur qui commente des diapositives.\n",
    "Transcrivez uniquement le discours du professeur, en bon français, sans ajouter de descriptions de diapositives.\n",
    "Ignorez les répétitions ou hésitations.\n",
    "Privilégiez la clarté.\n",
    "\"\"\"\n",
    "timestamp_granularities = [\"segment\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d97810c",
   "metadata": {},
   "source": [
    "# Transcription with timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3e2ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 16:52:05 - audio_extractor.transcription.whisper_client - INFO - Transcribing with timestamps: /Users/youssefjanjar/Documents/formascience/volume/audio/cours_1_audio_chunks/cours_1_audio_chunk_001.wav\n",
      "2025-07-27 16:52:17 - audio_extractor.transcription.whisper_client - INFO - Transcription saved: /Users/youssefjanjar/Documents/formascience/volume/transcripts/json/cours_1_audio_chunk_001_transcription.json\n",
      "2025-07-27 16:52:17 - audio_extractor.transcription.whisper_client - INFO - JSON transcription saved to: /Users/youssefjanjar/Documents/formascience/volume/transcripts/json/cours_1_audio_chunk_001_transcription.json\n",
      "2025-07-27 16:52:17 - audio_extractor.transcription.whisper_client - INFO - Parsed timestamps saved to: /Users/youssefjanjar/Documents/formascience/volume/transcripts/parsed/cours_1_audio_chunk_001_timestamps.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON saved to: /Users/youssefjanjar/Documents/formascience/volume/transcripts/json/cours_1_audio_chunk_001_transcription.json\n",
      "✅ Parsed timestamps saved to: /Users/youssefjanjar/Documents/formascience/volume/transcripts/parsed/cours_1_audio_chunk_001_timestamps.txt\n"
     ]
    }
   ],
   "source": [
    "# Your specific use case - French academic transcription\n",
    "from audio_extractor import WhisperTranscriber\n",
    "\n",
    "# Academic French transcription prompt\n",
    "prompt = \"\"\"\n",
    "Transcription académique d'un cours de médecine universitaire, en français.\n",
    "Le locuteur est un professeur qui commente des diapositives.\n",
    "Utilisez la terminologie médicale appropriée.\n",
    "Indiquez les pauses importantes par des points.\n",
    "Privilégiez la clarté.\n",
    "\"\"\"\n",
    "\n",
    "# Your audio file path\n",
    "audio_path = \"/Users/youssefjanjar/Documents/formascience/volume/audio/cours_1_audio_chunks/cours_1_audio_chunk_001.wav\"\n",
    "\n",
    "from audio_extractor import WhisperTranscriber\n",
    "\n",
    "transcriber = WhisperTranscriber()\n",
    "\n",
    "# French academic transcription with timestamp parsing\n",
    "result = transcriber.transcribe_with_timestamps(\n",
    "    audio_path=audio_path,\n",
    "    language=\"fr\",\n",
    "    prompt=prompt,\n",
    "    timestamp_granularities=[\"segment\"]\n",
    ")\n",
    "\n",
    "print(f\"✅ JSON saved to: {result['json_file']}\")\n",
    "print(f\"✅ Parsed timestamps saved to: {result['parsed_file']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9261e86c",
   "metadata": {},
   "source": [
    "# PDF extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01486bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting PDF metadata...\n",
      "Title: Présentation PowerPoint\n",
      "Author: Jean Muller\n",
      "Pages: 111\n",
      "\n",
      "Extracting slide content...\n",
      "\n",
      "Extraction Summary:\n",
      "- Total slides: 111\n",
      "- Total text: 31,988 characters\n",
      "- Total images: 591\n",
      "\n",
      "Parsing slide structure...\n",
      "\n",
      "Presentation: L1SpS: UE 2 Les molécules du vivant\n",
      "Introduction\n",
      "3\n",
      "Total slides: 111\n",
      "\n",
      "Main Topics:\n",
      "1. L1SpS: UE 2 Les molécules du vivant\n",
      "7.\n",
      "2. L1SpS: UE 2 Les molécules du vivant\n",
      "3. L1SpS: UE 2 Les molécules du vivant\n",
      "4. L1SpS: UE 2 Les molécules du vivant\n",
      "5. L1SpS: UE 2 Les molécules du vivant\n",
      "\n",
      "Key terms: molécules, vivant, l1sps, génome, gènes, gène, humain, génomes, répétés, variation\n",
      "\n",
      "Slide breakdown: 110 content slides, 0 summary slides\n",
      "\n",
      "Top 3 Most Important Slides:\n",
      "========================================\n",
      "\n",
      "Slide 1 - TEXT_HEAVY\n",
      "Importance Score: 1.00\n",
      "Title: L1SpS: UE 2 Les molécules du vivant\n",
      "7.\n",
      "Bullet Points:\n",
      "  • 1 Architecture du génome\n",
      "  • E.2 Les molécules du vivant\n",
      "  • Organisation du génome humain, méthodes en\n",
      "Keywords: molécules, vivant, génome, humain, laboratoire\n",
      "------------------------------\n",
      "\n",
      "Slide 2 - BULLET_LIST\n",
      "Importance Score: 1.00\n",
      "Title: L1SpS: UE 2 Les molécules du vivant\n",
      "Bullet Points:\n",
      "  • Introduction\n",
      "  • Notions fondamentales\n",
      "  • Le génome humain\n",
      "Keywords: génome, humain, notions, éléments, codants\n",
      "------------------------------\n",
      "\n",
      "Slide 4 - BULLET_LIST\n",
      "Importance Score: 1.00\n",
      "Title: L1SpS: UE 2 Les molécules du vivant\n",
      "Bullet Points:\n",
      "  • Evolution\n",
      "  • Temps\n",
      "  • Adaptation\n",
      "Keywords: l1sps, molécules, vivant, arbre, luca\n",
      "------------------------------\n",
      "\n",
      "Extracted text saved to: example_output/text/extracted_presentation.txt\n"
     ]
    }
   ],
   "source": [
    "from pdf_extractor.pdf_processor import PDFProcessor\n",
    "from pdf_extractor.slide_parser import SlideParser\n",
    "\n",
    "pdf_path = \"/Users/youssefjanjar/Documents/class_parser/volume/slides/cours_1.pdf\"\n",
    "\n",
    "\"\"\"Example of extracting and parsing PDF slides.\"\"\"\n",
    "\n",
    "# Initialize processor and parser\n",
    "processor = PDFProcessor(output_dir=\"/Users/youssefjanjar/Documents/class_parser/output\")\n",
    "parser = SlideParser()\n",
    "\n",
    "\n",
    "try:\n",
    "    # Extract PDF metadata\n",
    "    print(\"Extracting PDF metadata...\")\n",
    "    metadata = processor.extract_pdf_metadata(pdf_path)\n",
    "    print(f\"Title: {metadata.title}\")\n",
    "    print(f\"Author: {metadata.author}\")\n",
    "    print(f\"Pages: {metadata.page_count}\")\n",
    "    \n",
    "    # Extract slide content\n",
    "    print(\"\\nExtracting slide content...\")\n",
    "    slides = processor.extract_slide_content(\n",
    "        pdf_path=pdf_path,\n",
    "        extract_images=True,\n",
    "        convert_to_images=True,\n",
    "        dpi=300\n",
    "    )\n",
    "    \n",
    "    # Get extraction summary\n",
    "    summary = processor.get_extraction_summary(slides)\n",
    "    print(f\"\\nExtraction Summary:\")\n",
    "    print(f\"- Total slides: {summary['total_slides']}\")\n",
    "    print(f\"- Total text: {summary['total_text_length']:,} characters\")\n",
    "    print(f\"- Total images: {summary['total_images']}\")\n",
    "    \n",
    "    # Parse slides\n",
    "    print(\"\\nParsing slide structure...\")\n",
    "    parsed_slides = parser.parse_slides(slides)\n",
    "    \n",
    "    # Analyze presentation structure\n",
    "    structure = parser.analyze_presentation_structure(parsed_slides)\n",
    "    \n",
    "    # Generate summary\n",
    "    presentation_summary = parser.generate_presentation_summary(structure)\n",
    "    print(f\"\\n{presentation_summary}\")\n",
    "    \n",
    "    # Show detailed analysis for top 3 most important slides\n",
    "    print(\"\\nTop 3 Most Important Slides:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    top_slides = sorted(parsed_slides, key=lambda x: x.importance_score, reverse=True)[:3]\n",
    "    \n",
    "    for slide in top_slides:\n",
    "        print(f\"\\nSlide {slide.page_number} - {slide.slide_type.upper()}\")\n",
    "        print(f\"Importance Score: {slide.importance_score:.2f}\")\n",
    "        \n",
    "        if slide.title:\n",
    "            print(f\"Title: {slide.title}\")\n",
    "        \n",
    "        if slide.bullet_points:\n",
    "            print(f\"Bullet Points:\")\n",
    "            for bp in slide.bullet_points[:3]:\n",
    "                print(f\"  • {bp}\")\n",
    "        \n",
    "        if slide.keywords:\n",
    "            print(f\"Keywords: {', '.join(slide.keywords[:5])}\")\n",
    "        \n",
    "        print(\"-\" * 30)\n",
    "    \n",
    "    # Save extracted text\n",
    "    processor.save_extracted_text(slides, \"extracted_presentation.txt\")\n",
    "    print(f\"\\nExtracted text saved to: example_output/text/extracted_presentation.txt\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"PDF file not found: {pdf_path}\")\n",
    "    print(\"Please place a PDF file named 'example_presentation.pdf' in the current directory\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing PDF: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24498555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
